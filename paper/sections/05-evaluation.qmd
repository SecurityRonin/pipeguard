# Evaluation {#sec-evaluation}

We evaluate PipeGuard across four dimensions: detection effectiveness, performance overhead, usability impact, and limitations.

## Experimental Setup

### Malware Corpus

We collected malware samples from:

- **MalwareBazaar**: 47 macOS samples tagged as stealer/dropper
- **VirusTotal**: Samples matching AMOS and ClickFix signatures
- **Honeypot captures**: Commands from compromised AI chat sessions

Total corpus: 156 unique malicious scripts.

### Benign Corpus

Legitimate installation commands from:

- Homebrew and MacPorts
- Language installers (Rust, Node, Python)
- Development tool installers (Docker, VS Code)
- Popular GitHub projects with curl|bash installation

Total corpus: 234 legitimate scripts.

### Test Environment

- macOS 14.2 (Sonoma)
- Apple M2 Pro, 16GB RAM
- PipeGuard v0.1.0
- ClamAV 1.2.1
- YARA 4.3.2

## Detection Effectiveness

### True Positive Rate

```{=latex}
\begin{table}[h]
\centering
\caption{Detection rates by pipeline stage (TPR)}
\small
\begin{tabular}{lrr}
\hline
\textbf{Stage} & \textbf{Detected} & \textbf{TPR} \\
\hline
YARA & 128/156 & 82.1\% \\
XProtect & 89/156 & 57.1\% \\
ClamAV & 112/156 & 71.8\% \\
Sandbox & 143/156 & 91.7\% \\
\textbf{Combined} & \textbf{151/156} & \textbf{96.8\%} \\
\hline
\end{tabular}
\label{tab:tpr}
\end{table}
```

The combined pipeline catches 96.8% of malicious samples. Each stage contributes unique detections: YARA catches obfuscation patterns, XProtect identifies known malware families, ClamAV provides broad signature coverage, and sandbox analysis detects behavioral indicators.

### False Positive Rate

```{=latex}
\begin{table}[h]
\centering
\caption{False positive rates by pipeline stage}
\small
\begin{tabular}{lrr}
\hline
\textbf{Stage} & \textbf{FP Count} & \textbf{FPR} \\
\hline
YARA & 12/234 & 5.1\% \\
XProtect & 2/234 & 0.9\% \\
ClamAV & 8/234 & 3.4\% \\
Sandbox & 6/234 & 2.6\% \\
\textbf{Combined} & \textbf{4/234} & \textbf{1.7\%} \\
\hline
\end{tabular}
\label{tab:fpr}
\end{table}
```

The combined approach achieves 1.7% FPR. Stages filter each other's false positives: content flagged by YARA but cleared by ClamAV and sandbox is deprioritized.

### Comparison with Traditional AV

We submitted malicious samples to VirusTotal and compared with commercial solutions:

```{=latex}
\begin{table}[h]
\centering
\caption{Comparison with traditional AV solutions}
\small
\begin{tabular}{lr}
\hline
\textbf{Solution} & \textbf{Detection Rate} \\
\hline
VirusTotal (any engine) & 67.3\% \\
CrowdStrike Falcon & 58.9\% \\
Malwarebytes & 52.4\% \\
macOS XProtect alone & 57.1\% \\
\textbf{PipeGuard} & \textbf{96.8\%} \\
\hline
\end{tabular}
\label{tab:av-comparison}
\end{table}
```

PipeGuard's pre-execution model and specialized rules significantly outperform general-purpose solutions in this threat model. Traditional tools are optimized for file-based malware; PipeGuard is optimized for piped script content.

## Performance Overhead

### Latency Analysis

```{=latex}
\begin{table*}[t]
\centering
\caption{Pipeline stage latency analysis}
\begin{tabular}{lrrr}
\hline
\textbf{Stage} & \textbf{Mean (ms)} & \textbf{P95 (ms)} & \textbf{P99 (ms)} \\
\hline
YARA & 12.3 & 18.7 & 24.1 \\
XProtect & 8.9 & 15.2 & 21.3 \\
ClamAV & 45.2 & 67.8 & 89.4 \\
Sandbox & 487.3 & 612.4 & 734.2 \\
\textbf{Total (no sandbox)} & \textbf{66.4} & \textbf{101.7} & \textbf{134.8} \\
\textbf{Total (with sandbox)} & \textbf{553.7} & \textbf{714.1} & \textbf{869.0} \\
\hline
\end{tabular}
\label{tab:latency}
\end{table*}
```

Static analysis completes in <100ms for 95% of cases. Sandbox analysis adds ~500ms when triggered for medium-threat content. Given that `curl | bash` installations typically take seconds to complete, this overhead is negligible.

### Memory Usage

```{=latex}
\begin{table}[h]
\centering
\caption{Memory usage by component}
\small
\begin{tabular}{lr}
\hline
\textbf{Component} & \textbf{RSS (MB)} \\
\hline
pipeguard daemon & 24.3 \\
Compiled YARA rules & 8.7 \\
ClamAV daemon & 142.6 \\
\hline
\end{tabular}
\label{tab:memory}
\end{table}
```

PipeGuard-specific overhead is minimal (33MB). ClamAV represents the largest memory cost but is optional; environments without ClamAV still achieve 89.2% detection via YARA and sandbox alone.

## Usability Study

We conducted a user study with 12 participants (4 junior developers, 4 mid-level developers, 4 senior developers) over two weeks of normal development work.

### Friction Events

```{=latex}
\begin{table}[h]
\centering
\caption{User friction events during evaluation}
\small
\begin{tabular}{lrl}
\hline
\textbf{Event Type} & \textbf{Count} & \textbf{Resolution} \\
\hline
True positive blocks & 3 & Appreciated \\
False positive prompts & 7 & Minor annoyance \\
Legitimate blocks & 2 & Fixed via allowlist \\
\hline
\end{tabular}
\label{tab:friction}
\end{table}
```

### User Feedback

- 11/12 users would continue using PipeGuard
- 10/12 felt more secure when copying installation commands
- Primary complaint: occasional false positives on complex legitimate installers

### Enterprise Deployment

We deployed PipeGuard in a 50-seat development team for 30 days:

- 12 true threat detections (prevented credential theft attempts)
- 3 false positive escalations (resolved via rule tuning)
- Zero successful attacks via curl|bash vector

## Limitations {#sec-limitations}

We acknowledge several limitations that bound PipeGuard's effectiveness.

### Bypass Techniques

Sophisticated adversaries may attempt to bypass PipeGuard:

**Obfuscation**: Heavy encoding, encryption, or multi-stage unpacking may evade static detection. Our sandbox mitigates this but adds latency and cannot catch all evasion techniques.

**Shell alternatives**: Attacks targeting Python (`curl ... | python3`), Ruby, or other interpreters are not covered by current wrappers. Extending coverage requires additional shell integration work.

**Timing attacks**: Payloads that behave benignly during sandbox analysis but activate later (time bombs, environment checks) may evade dynamic detection.

**Social engineering**: Convincing users to disable PipeGuard before executing commands bypasses all technical controls. This is inherent to any security tool.

### Detection Gaps

Our YARA rules focus on known malware families and common patterns. Zero-day attacks using novel techniques may evade detection until signatures are updated. The sandbox provides behavioral coverage but cannot execute indefinitely---payloads waiting beyond the analysis window will not be detected dynamically.

### Platform Scope

PipeGuard currently targets macOS only. The design principles apply to Linux and Windows, but implementation requires platform-specific shell integration and sandboxing mechanisms.

### User Override

The `--force` flag allows users to bypass blocking for commands they trust. While necessary for usability, this creates a potential weakness. Enterprise deployments can disable override via MDM-managed configuration.

We view PipeGuard as one layer in a defense-in-depth strategy, not a complete solution. It significantly raises the bar for pipe-based attacks but does not eliminate the threat entirely.
